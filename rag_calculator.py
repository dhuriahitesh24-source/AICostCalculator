import streamlit as st
import pandas as pd

# --- CONFIGURATION & STYLING ---
st.set_page_config(page_title="Azure RAG Cost Canvas", layout="wide")
st.title("üí∞ Azure GenAI & RAG Cost Canvas")
st.markdown("""
This calculator breaks down costs for **Client BBB** into two phases:
1. **One-Time Processing:** Ingesting 1,000 sessions (STT + SUD Generation).
2. **Recurring Monthly:** 500 Users querying the RAG Knowledge Base.
""")

# --- SIDEBAR: GLOBAL PARAMETERS ---
st.sidebar.header("‚öôÔ∏è Unit Pricing (Azure)")
cost_stt_batch = st.sidebar.number_input("Azure Speech Batch ($/hr)", value=0.36, format="%.4f")
cost_gpt4o_in = st.sidebar.number_input("GPT-4o Input ($/1M tokens)", value=2.50, format="%.2f")
cost_gpt4o_out = st.sidebar.number_input("GPT-4o Output ($/1M tokens)", value=10.00, format="%.2f")
cost_embed = st.sidebar.number_input("Embeddings ($/1M tokens)", value=0.02, format="%.4f")

# --- TAB 1: ONE-TIME PROCESSING (INGESTION) ---
tab1, tab2, tab3 = st.tabs(["üèóÔ∏è Phase 1: Ingestion", "üîÑ Phase 2: Monthly RAG", "üìâ Combined Summary"])

with tab1:
    st.header("Phase 1: Knowledge Ingestion (One-Time)")
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("Volume Assumptions")
        num_sessions = st.number_input("Number of Sessions", value=1000)
        avg_duration = st.number_input("Avg Duration (Hours)", value=1.5)
        words_per_hour = st.number_input("Avg Words per Hour", value=9000)
    
    # Calculations
    total_hours = num_sessions * avg_duration
    total_words = total_hours * words_per_hour
    # Estimate tokens: 1 word ~= 1.33 tokens, plus overhead
    total_transcript_tokens = total_words * 1.35 
    # SUD Output: Assume ~500 words summary per session
    total_sud_output_tokens = num_sessions * 750 

    # Costs
    cost_stt_total = total_hours * cost_stt_batch
    cost_gpt_input_total = (total_transcript_tokens / 1_000_000) * cost_gpt4o_in
    cost_gpt_output_total = (total_sud_output_tokens / 1_000_000) * cost_gpt4o_out
    
    phase1_total = cost_stt_total + cost_gpt_input_total + cost_gpt_output_total

    with col2:
        st.subheader("üí∞ Phase 1 Cost Estimate")
        st.metric(label="Total One-Time Cost", value=f"${phase1_total:,.2f}")
        
        # Detailed Breakdown Table
        df_p1 = pd.DataFrame({
            "Component": ["Speech-to-Text (Batch)", "GPT-4o Analysis (Input)", "GPT-4o SUD Gen (Output)"],
            "Volume": [f"{total_hours:,.0f} hrs", f"{total_transcript_tokens/1e6:.1f}M tokens", f"{total_sud_output_tokens/1e6:.1f}M tokens"],
            "Cost": [cost_stt_total, cost_gpt_input_total, cost_gpt_output_total]
        })
        st.dataframe(df_p1.style.format({"Cost": "${:,.2f}"}), use_container_width=True)

# --- TAB 2: RECURRING OPERATIONS (RAG) ---
with tab2:
    st.header("Phase 2: RAG Knowledge Retrieval (Monthly)")
    col_r1, col_r2 = st.columns(2)
    
    with col_r1:
        st.subheader("User Behavior")
        num_users = st.number_input("Active Users", value=500)
        queries_per_day = st.number_input("Queries per User/Day", value=30)
        work_days = st.number_input("Working Days/Month", value=30)
        
        st.subheader("RAG Payload Size (Tokens)")
        tokens_context = st.number_input("Context per Query (Input)", value=1500, help="Chunks retrieved from Vector DB sent to LLM")
        tokens_answer = st.number_input("Answer Size (Output)", value=200, help="The final answer generated by GPT-4o")

    # Calculations
    monthly_queries = num_users * queries_per_day * work_days
    monthly_input_tokens = monthly_queries * (tokens_context + 50) # +50 for user question
    monthly_output_tokens = monthly_queries * tokens_answer
    
    # Infrastructure Costs (Fixed Estimates based on previous chat)
    st.subheader("Infrastructure Fixed Costs")
    cost_apim = st.number_input("Azure APIM (Basic)", value=48.04)
    cost_nat = st.number_input("NAT Gateway + IP", value=39.30)
    cost_func = st.number_input("Azure Functions (Premium)", value=45.00)
    
    # AI Costs
    cost_rag_input = (monthly_input_tokens / 1_000_000) * cost_gpt4o_in
    cost_rag_output = (monthly_output_tokens / 1_000_000) * cost_gpt4o_out
    cost_embeddings = (monthly_queries * 100 / 1_000_000) * cost_embed # Cheap
    
    phase2_total = cost_rag_input + cost_rag_output + cost_embeddings + cost_apim + cost_nat + cost_func

    with col_r2:
        st.subheader("üí∞ Monthly Recurring Cost")
        st.metric(label="Total Monthly Bill", value=f"${phase2_total:,.2f}")
        st.info(f"Cost per User: **${phase2_total/num_users:,.2f} / month**")
        
        df_p2 = pd.DataFrame({
            "Component": ["GPT-4o Input (Context)", "GPT-4o Output (Answers)", "Infrastructure (APIM/NAT/Func)", "Embeddings"],
            "Volume": [f"{monthly_input_tokens/1e6:.1f}M tokens", f"{monthly_output_tokens/1e6:.1f}M tokens", "Flat Rate", f"{monthly_queries:,.0f} queries"],
            "Cost": [cost_rag_input, cost_rag_output, (cost_apim + cost_nat + cost_func), cost_embeddings]
        })
        st.dataframe(df_p2.style.format({"Cost": "${:,.2f}"}), use_container_width=True)

# --- TAB 3: SUMMARY ---
with tab3:
    st.header("üìâ Executive Summary")
    
    col_sum1, col_sum2, col_sum3 = st.columns(3)
    col_sum1.metric("One-Time Investment", f"${phase1_total:,.2f}", "Ingestion")
    col_sum2.metric("Monthly OpEx", f"${phase2_total:,.2f}", "Recurring")
    col_sum3.metric("Annual Run Rate", f"${(phase2_total * 12):,.2f}", "Year 1 OpEx")

    st.warning("‚ö†Ô∏è **Note:** This estimate excludes AWS Redis costs (Vendor AAA) and data egress fees (minimal).")
